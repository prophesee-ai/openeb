name: All Build on PR

on:
  workflow_dispatch:
  push:
  pull_request:

env:
  #General variables
  numpy_version: "numpy==1.19.5" # replace with only 'numpy' if no version needed
  python_versions: 3.8
  pybind_version: "2.4.3"
  #Windows variables
  python_executable: "C:/hostedtoolcache/windows/Python/3.8.10/x64/python.exe" #Cmake needs this to find python on windows
  HAL_plugins_win: "https://files.prophesee.ai/share/dists/public/windows/cp51Vn3b/Metavision_HAL_Prophesee_plugins_222_Setup.exe"
  #Ubuntu variables
  HAL_plugins_source: "https://files.prophesee.ai/redir/quah3Xei9ahgaiKa"

jobs:

  job1:
    name: Ubuntu 20
    runs-on: ubuntu-20.04
    steps:

    - name: Checkout Repository
      uses: actions/checkout@v2

    - name: Install dependencies
      run: |
          sudo apt-get -y update && sudo apt-get install -y sudo apt-utils wget cmake build-essential \
          libglew-dev git g++ libusb-1.0-0-dev libeigen3-dev libgtest-dev libssl-dev \
          python3-pip python3-distutils xvfb libglfw3 libglfw3-dev libglew-dev libopencv-dev ffmpeg \
          libboost-dev libboost-program-options-dev libboost-filesystem-dev libboost-timer-dev \
          libboost-chrono-dev libboost-thread-dev zip unzip python3-pybind11 git-lfs
          pip install opencv-python $numpy_version pytest

    - name: Build openEB
      run: |
          mkdir build ; cd build
          cmake .. -DBUILD_TESTING=ON
          cmake --build . --config Release --parallel 4

    - name: Download and Install HAL Plugins
      shell: bash
      run: |
          curl -L -o source.list $HAL_plugins_source
          cat source.list | sudo tee -a /etc/apt/sources.list
          sudo apt update
          sudo apt install metavision-hal-prophesee-plugins

    - name : Getting datasets from storage
      uses: dawidd6/action-download-artifact@v2
      with:
        workflow: upload_datasets_on_schedule.yaml
        workflow_conclusion: success
        name: datasets
        path: datasets

    - name: Run ctest
      run: |
          cd build
          ctest --output-on-failure

  job2:
    name: Ubuntu 18
    runs-on: ubuntu-18.04
    steps:

    - name: Checkout Repository
      uses: actions/checkout@v2

    - name: Install dependencies
      run: |
          sudo apt-get -y update && sudo apt-get install -y sudo apt-utils wget cmake build-essential \
          libglew-dev git g++ libusb-1.0-0-dev libeigen3-dev libgtest-dev libssl-dev \
          python3-pip python3-distutils xvfb libglfw3 libglfw3-dev libglew-dev libopencv-dev ffmpeg \
          libboost-dev libboost-program-options-dev libboost-filesystem-dev libboost-timer-dev \
          libboost-chrono-dev libboost-thread-dev zip unzip
          python3 -m pip install --upgrade pip
          python3 -m pip install opencv-python $numpy_version pytest

    - name: Build pybind, gtest, and openEB
      run: |
          openebfolder=${PWD}
          cd ..
          wget https://github.com/pybind/pybind11/archive/v$pybind_version.zip
          unzip v$pybind_version.zip
          cd pybind11-$pybind_version/
          mkdir build && cd build
          cmake .. -DPYBIND11_TEST=OFF
          cmake --build .
          make
          sudo make install
          cd /usr/src/gtest/
          sudo cmake .
          sudo make
          sudo cp libgtest.a libgtest_main.a /usr/local/lib/
          cd $openebfolder
          mkdir build ; cd build
          cmake .. -DBUILD_TESTING=ON
          cmake --build . --config Release --parallel 4

    - name: Download and Install HAL Plugins
      shell: bash
      run: |
          curl -L -o source.list $HAL_plugins_source
          cat source.list | sudo tee -a /etc/apt/sources.list
          sudo apt update
          sudo apt install metavision-hal-prophesee-plugins

    - name : Getting datasets from storage
      uses: dawidd6/action-download-artifact@v2
      with:
        workflow: upload_datasets_on_schedule.yaml
        workflow_conclusion: success
        name: datasets
        path: datasets

    - name: Run ctest
      run: |
          cd build
          ctest --output-on-failure

  job3:
    name: Windows
    runs-on: windows-2019
    steps:

    - name: Checkout Repository
      uses: actions/checkout@v2

    - name: Setup Python
      uses: actions/setup-python@v2.2.2
      with: 
       python-version: ${{ env.python_versions }}

    - name: Setup Miniconda
      uses: conda-incubator/setup-miniconda@v2.1.1
      with: 
        python-version: ${{ env.python_versions }}

    - name: Install python and Conda dependencies
      shell: bash
      run: | 
        py -$python_versions -m pip install pytest $numpy_version opencv-python
        $CONDA/condabin/conda.bat install -c conda-forge $numpy_version libusb eigen boost opencv glfw glew gtest dirent pybind11==$pybind_version libopencv

    - name: Build openEB
      shell: bash
      run: |
          mkdir build && cd build
          cmake -A x64 -DCMAKE_PREFIX_PATH="$CONDA/envs/test/Library" \
                -D Python3_EXECUTABLE=$python_executable \
                -DBUILD_TESTING=ON ..
          cmake --build . --config Release --parallel 4

    - name: Download HAL Plugins and move DLLs into /build
      shell: bash
      run: |
          ls build/py3/Release
          find C:/Miniconda/envs/test -name '*.dll' -exec cp "{}" build/py3/Release \;
          ls build/py3/Release
          cp -r build/py3/Release/{boost,lib}*.dll build/bin/Release
          ls build/bin/Release
          curl -L -u ${{ secrets.PROPHESEE_HAL_PLUGIN_CURL_DOWNLOAD_CREDENTIALS }} -o Metavision_Hal_Prophesee_plugins_Setup.exe $HAL_plugins_win

    - name: Install HAL Plugins
      shell: powershell
      run: d:\a\openeb\openeb\Metavision_Hal_Prophesee_plugins_Setup.exe /VERYSILENT /SUPPRESSMSGBOXES
      
    - name : Getting datasets from storage
      uses: dawidd6/action-download-artifact@v2
      with:
        workflow: upload_datasets_on_schedule.yaml
        workflow_conclusion: success
        name: datasets
        path: datasets

    - name: Ctest suite
      shell: powershell
      run: |
        cd build
        ctest -C Release --output-on-failure

  CI_results:
    runs-on: ubuntu-latest
    if: always()
    steps:
    
      # - name: Check test results
      #   if: ${{ failure() }}
      #   run: |
      #     if [[ "${{ needs.job1.outputs.result }}" == "Success" && "${{ needs.job2.outputs.job.status }}" == "Success" \
      #     && "${{ needs.job3.outputs.job.status }}" == "Success" ]]; then
      #     $results="Success"
      #     fi

      - name: Slack PR hook test
        uses: kingarrkinian/slack-pr-open-notification-action@no_fork_option
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.OPENEB_GITHUB_PROPHESEE_SLACK_WEBHOOK }}
          PULL_REQUEST_NUMBER : ${{ github.event.pull_request.number }}
          PULL_REQUEST_TITLE : ${{ github.event.pull_request.title }}
          PULL_REQUEST_AUTHOR_NAME : ${{ github.event.pull_request.user.login }}
          PULL_REQUEST_AUTHOR_ICON_URL : ${{ github.event.pull_request.user.avatar_url }}
          PULL_REQUEST_URL : ${{ github.event.pull_request.html_url }}
          PULL_REQUEST_BODY : ${{ github.event.pull_request.body }}
          PULL_REQUEST_BASE_REPO_NAME: ${{ github.event.pull_request.base.repo.name }}
          PULL_REQUEST_COMPARE_BRANCH_OWNER: ${{ github.event.pull_request.head.repo.owner.login }}
          PULL_REQUEST_COMPARE_BRANCH_NAME : ${{ github.event.pull_request.head.ref }}
          PULL_REQUEST_BASE_BRANCH_OWNER: ${{ github.event.pull_request.base.repo.owner.login }}
          PULL_REQUEST_BASE_BRANCH_NAME : ${{ github.event.pull_request.base.ref }}
          IS_SEND_HERE_MENTION : false
          MAKE_PRETTY : true
          MAKE_COMPACT : false